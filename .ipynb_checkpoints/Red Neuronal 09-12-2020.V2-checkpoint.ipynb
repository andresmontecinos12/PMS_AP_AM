{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#librerias de manejo de datos\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#Modelos\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "\n",
    "#librerias de visualización\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "pd.set_option('display.max_columns', 500)  # Ver más columnas de los dataframes\n",
    "from matplotlib import style\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "\n",
    "# Ver gráficos de matplotlib en jupyter notebook/lab\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# Selección de las variables por típo\n",
    "# ==============================================================================\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import make_column_selector\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV,RepeatedKFold\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "#otros\n",
    "import multiprocessing\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#from fitter import Fitter, get_common_distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importar Datos Modelo ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CommandNotFoundError: No command 'conda to'.\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install xlrd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Missing optional dependency 'xlrd'. Install xlrd >= 1.0.0 for Excel support Use pip or conda to install xlrd.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-f5802c4c435b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlibro\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"modelo.xlsx\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdatos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibro\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msheet_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Andres Sabella'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdatos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Ubicación\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Factor Sección Característica\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Tipo Pavimento\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Área (m2)\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"NOMENCLATURA\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"EDAD PAVIMENTO\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"PCI\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"DELTA PCI\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"CARGA ACUMULADA RUEDA SIMPLE\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"CARGA ACUMULADA RUEDA DOBLE\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"CARGA ACUMULADA RUEDA DOBLE TANDEM\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"CORREGIR EDAD-TRANSITO\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdatos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"PCI OBJETIVO\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/PMS/lib/python3.8/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    297\u001b[0m                 )\n\u001b[1;32m    298\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/PMS/lib/python3.8/site-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m         \u001b[0mio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         raise ValueError(\n",
      "\u001b[0;32m~/miniconda3/envs/PMS/lib/python3.8/site-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[1;32m   1107\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage_options\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1109\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__fspath__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/PMS/lib/python3.8/site-packages/pandas/io/excel/_xlrd.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filepath_or_buffer, storage_options)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \"\"\"\n\u001b[1;32m     23\u001b[0m         \u001b[0merr_msg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Install xlrd >= 1.0.0 for Excel support\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mimport_optional_dependency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"xlrd\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/PMS/lib/python3.8/site-packages/pandas/compat/_optional.py\u001b[0m in \u001b[0;36mimport_optional_dependency\u001b[0;34m(name, extra, raise_on_missing, on_version)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mraise_on_missing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: Missing optional dependency 'xlrd'. Install xlrd >= 1.0.0 for Excel support Use pip or conda to install xlrd."
     ]
    }
   ],
   "source": [
    "libro=\"modelo.xlsx\"\n",
    "datos=pd.read_excel(libro,sheet_name='Andres Sabella')\n",
    "x=datos[[\"Ubicación\",\"Factor Sección Característica\",\"Tipo Pavimento\",\"Área (m2)\",\"NOMENCLATURA\",\"EDAD PAVIMENTO\",\"PCI\",\"DELTA PCI\",\"CARGA ACUMULADA RUEDA SIMPLE\",\"CARGA ACUMULADA RUEDA DOBLE\",\"CARGA ACUMULADA RUEDA DOBLE TANDEM\",\"CORREGIR EDAD-TRANSITO\"]]\n",
    "y=datos[[\"PCI OBJETIVO\"]]\n",
    "df=pd.DataFrame(x)\n",
    "x=df.fillna(\"S-M\") # No se emplea  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#plt.scatter(y_test,pr.predict(X_test))\n",
    "fig, ax_0 = plt.subplots()\n",
    "ax_0.scatter(x[\"EDAD PAVIMENTO\"], x[\"PCI\"], edgecolors=(0, 0, 0),label='')\n",
    "#ax_0.plot([y_train.min(), y_train.max()], [0, 100], 'k--', lw=4)\n",
    "ax_0.set_xlabel('Edad del Pavimento')\n",
    "ax_0.set_ylabel('PCI')\n",
    "plt.ylim(0,100)\n",
    "ax_0.set_title('Andrés Sabella')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#FILTRAR DATOS DE ANALISIS DEJANDO FUERA A DATOS RELACIONADOS CON LA PLATAFORMA (PAVIMENTOS DE HORMIGÓN MÁS DE 40 AÑOS DE SERVICIO)\n",
    "\n",
    "x=datos[[\"Ubicación\",\"Factor Sección Característica\",\"Tipo Pavimento\",\"Área (m2)\",\"NOMENCLATURA\",\"EDAD PAVIMENTO\",\"PCI\",\"DELTA PCI\",\"CARGA ACUMULADA RUEDA SIMPLE\",\"CARGA ACUMULADA RUEDA DOBLE\",\"CARGA ACUMULADA RUEDA DOBLE TANDEM\",\"CORREGIR EDAD-TRANSITO\",'PCI OBJETIVO',\"OPERACIONES EQUIVALENTES\"]]\n",
    "#mask=x['Ubicación']!='Plataforma'\n",
    "mask2=x['OPERACIONES EQUIVALENTES']>=0\n",
    "#mask3=x[\"DELTA PCI\"]==0\n",
    "x=x[mask2]\n",
    "y=x['PCI OBJETIVO']\n",
    "x=x.drop('PCI OBJETIVO',axis=1)\n",
    "x.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datos de Entradas ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#TIPOS DE DATOS A ANALIZADOS\n",
    "x.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#REVISAR SI HAY VALORES NULOS EN LOS DATOS ANALIZADOS\n",
    "x.isna().sum().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#ANALIZAR DISTRIBUCIÓN DE DATOS DE SALIDA\n",
    "\n",
    "fig, axes = plt.subplots(nrows=3, ncols=1, figsize=(10, 10))\n",
    "sns.distplot(\n",
    "    y,\n",
    "    hist    = False,\n",
    "    rug     = True,\n",
    "    color   = \"blue\",\n",
    "    kde_kws = {'shade': True, 'linewidth': 1},\n",
    "    ax      = axes[0]\n",
    ")\n",
    "axes[0].set_title(\"Distribución original\", fontsize = 'medium')\n",
    "axes[0].set_xlabel('precio', fontsize='small') \n",
    "axes[0].tick_params(labelsize = 6)\n",
    "\n",
    "sns.distplot(\n",
    "    np.sqrt(y),\n",
    "    hist    = False,\n",
    "    rug     = True,\n",
    "    color   = \"blue\",\n",
    "    kde_kws = {'shade': True, 'linewidth': 1},\n",
    "    ax      = axes[1]\n",
    ")\n",
    "axes[1].set_title(\"Transformación raíz cuadrada\", fontsize = 'medium')\n",
    "axes[1].set_xlabel('sqrt(precio)', fontsize='small') \n",
    "axes[1].tick_params(labelsize = 6)\n",
    "\n",
    "sns.distplot(\n",
    "    np.log(y),\n",
    "    hist    = False,\n",
    "    rug     = True,\n",
    "    color   = \"blue\",\n",
    "    kde_kws = {'shade': True, 'linewidth': 1},\n",
    "    ax      = axes[2]\n",
    ")\n",
    "axes[2].set_title(\"Transformación logarítmica\", fontsize = 'medium')\n",
    "axes[2].set_xlabel('log(precio)', fontsize='small') \n",
    "axes[2].tick_params(labelsize = 6)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#mejor ajuste regresión tipo beta\n",
    "\n",
    "distribuciones = ['cauchy', 'chi2', 'expon',  'exponpow', 'gamma',\n",
    "                  'norm', 'powerlaw', 'beta', 'logistic']\n",
    "\n",
    "fitter = Fitter(y, distributions=distribuciones)\n",
    "fitter.fit()\n",
    "fitter.summary(Nbest=10, plot=False).sort_values('sumsquare_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Variables numéricas\n",
    "# ==============================================================================\n",
    "x.select_dtypes(include=['float64', 'int64']).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Gráfico de distribución para cada variable numérica\n",
    "# ==============================================================================\n",
    "# Ajustar número de subplots en función del número de columnas\n",
    "fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(15, 8))\n",
    "axes = axes.flat\n",
    "columnas_numeric = x.select_dtypes(include=['float64', 'int64']).columns\n",
    "#columnas_numeric = columnas_numeric.drop('')\n",
    "\n",
    "for i, colum in enumerate(columnas_numeric):\n",
    "    sns.histplot(\n",
    "        data    = x,\n",
    "        x       = colum,\n",
    "        stat    = \"count\",\n",
    "        kde     = True,\n",
    "        color   = (list(plt.rcParams['axes.prop_cycle'])*2)[i][\"color\"],\n",
    "        line_kws= {'linewidth': 2},\n",
    "        alpha   = 0.3,\n",
    "        ax      = axes[i]\n",
    "    )\n",
    "    axes[i].set_title(colum, fontsize = 7, fontweight = \"bold\")\n",
    "    axes[i].tick_params(labelsize = 6)\n",
    "    axes[i].set_xlabel(\"\")\n",
    "    \n",
    "    \n",
    "fig.tight_layout()\n",
    "plt.subplots_adjust(top = 0.9)\n",
    "fig.suptitle('Distribución variables numéricas', fontsize = 10, fontweight = \"bold\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La variable corregir EDAD-Tránsito debe ser dejada fuera del analisis dado que posee tan solo un valor numérico. Inicialmente fue creada para identificar los pavimentos de más de 40 años de edad y con valores de PCI sobre 80, por otro lado el modelo creado para predecir el tránsito acumulado fue creado a partir del año 2000 no prediciendo para años anteriores.\n",
    "\n",
    "La variable delta PCI preferentemente es 0, para mejorar el modelo pudiesen crearse variables ficcticias para representar bien el fenomeno de intervención de los pavimentos. Generando una especie de balanceo de clases tal como ocurre en problemas de clasificación.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x\n",
    "#Eliminar la variable CORREGIR EDAD-TRANSITO.\n",
    "# Gráfico de distribución para cada variable numérica\n",
    "# ==============================================================================\n",
    "# Ajustar número de subplots en función del número de columnas\n",
    "fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(15, 8))\n",
    "axes = axes.flat\n",
    "\n",
    "columnas_numeric = x.select_dtypes(include=['float64', 'int64']).columns\n",
    "columnas_numeric = columnas_numeric.drop('CORREGIR EDAD-TRANSITO')\n",
    "for i, colum in enumerate(columnas_numeric):\n",
    "    sns.regplot(\n",
    "        x           = x[colum],\n",
    "        y           = y,\n",
    "        color       = \"gray\",\n",
    "        marker      = '.',\n",
    "        scatter_kws = {\"alpha\":0.4},\n",
    "        line_kws    = {\"color\":\"r\",\"alpha\":0.7},\n",
    "        ax          = axes[i],\n",
    "        #ci=None\n",
    "    )\n",
    "    axes[i].set_title(f\"PCI OBJETIVO vs {colum}\", fontsize = 7, fontweight = \"bold\")\n",
    "    #axes[i].ticklabel_format(style='sci', scilimits=(-4,4), axis='both')\n",
    "    axes[i].yaxis.set_major_formatter(ticker.EngFormatter())\n",
    "    axes[i].xaxis.set_major_formatter(ticker.EngFormatter())\n",
    "    axes[i].tick_params(labelsize = 6)\n",
    "    axes[i].set_xlabel(\"\")\n",
    "    axes[i].set_ylabel(\"\")\n",
    "\n",
    "# Se eliminan los axes vacíos\n",
    "for i in [8]:\n",
    "    fig.delaxes(axes[i])\n",
    "    \n",
    "fig.tight_layout()\n",
    "plt.subplots_adjust(top=0.9)\n",
    "fig.suptitle('Correlación con precio', fontsize = 10, fontweight = \"bold\");\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlación entre columnas numéricas\n",
    "# ==============================================================================\n",
    "\n",
    "def tidy_corr_matrix(corr_mat):\n",
    "    '''\n",
    "    Función para convertir una matrix de correlación de pandas en formato tidy\n",
    "    '''\n",
    "    corr_mat = corr_mat.stack().reset_index()\n",
    "    corr_mat.columns = ['variable_1','variable_2','r']\n",
    "    corr_mat = corr_mat.loc[corr_mat['variable_1'] != corr_mat['variable_2'], :]\n",
    "    corr_mat['abs_r'] = np.abs(corr_mat['r'])\n",
    "    corr_mat = corr_mat.sort_values('abs_r', ascending=False)\n",
    "    \n",
    "    return(corr_mat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x1=x.drop(['CARGA ACUMULADA RUEDA DOBLE', 'CARGA ACUMULADA RUEDA SIMPLE','CARGA ACUMULADA RUEDA DOBLE TANDEM','CORREGIR EDAD-TRANSITO'], axis=1)\n",
    "x11=x1\n",
    "corr_matrix1 = x1.select_dtypes(include=['float64', 'int64']).corr(method='pearson')\n",
    "tidy_corr_matrix(corr_matrix1).head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap matriz de correlaciones\n",
    "# ==============================================================================\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(10, 10))\n",
    "\n",
    "sns.heatmap(\n",
    "    corr_matrix1,\n",
    "    annot     = True,\n",
    "    cbar      = True,\n",
    "    annot_kws = {\"size\": 10},\n",
    "    vmin      = -1,\n",
    "    vmax      = 1,\n",
    "    center    = 0,\n",
    "    cmap      = sns.diverging_palette(20, 220, n=200),\n",
    "    square    = True,\n",
    "    ax        = ax\n",
    ")\n",
    "ax.set_xticklabels(\n",
    "    ax.get_xticklabels(),\n",
    "    rotation = 45,\n",
    "    horizontalalignment = 'right',\n",
    ")\n",
    "\n",
    "ax.tick_params(labelsize = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DESCRIPCION VARIABLES CUALITATIVAS\n",
    "\n",
    "# Variables cualitativas (tipo object)\n",
    "# ==============================================================================\n",
    "#x=x.drop('Tipo Pavimento',axis=1)\n",
    "x.select_dtypes(include=['object']).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Gráfico para cada variable cualitativa\n",
    "# ==============================================================================\n",
    "# Ajustar número de subplots en función del número de columnas\n",
    "fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(8, 6))\n",
    "axes = axes.flat\n",
    "columnas_object = x.select_dtypes(include=['object']).columns\n",
    "\n",
    "for i, colum in enumerate(columnas_object):\n",
    "    x[colum].value_counts().plot.barh(ax = axes[i])\n",
    "    axes[i].set_title(colum, fontsize = 9, fontweight = \"bold\")\n",
    "    axes[i].tick_params(labelsize = 9)\n",
    "    axes[i].set_xlabel(\"\")\n",
    "\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.subplots_adjust(top=0.9)\n",
    "fig.suptitle('Distribución variables cualitativas',\n",
    "             fontsize = 12, fontweight = \"bold\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREPROCESAMIENTO DE DATOS ## \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(\n",
    "                                        x1,\n",
    "                                        y,\n",
    "                                        train_size   = 0.8,\n",
    "                                        random_state = 43,\n",
    "                                        shuffle      = True\n",
    "                                    )\n",
    "print(\"Partición de entrenamento\")\n",
    "print(\"-----------------------\")\n",
    "print(y_train1.describe())\n",
    "\n",
    "\n",
    "print(\"Partición de test\")\n",
    "print(\"-----------------------\")\n",
    "print(y_test1.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Pipe: preprocesado\n",
    "\n",
    "numeric_cols = X_train1.select_dtypes(include=['float64', 'int64']).columns.to_list()\n",
    "cat_cols = X_train1.select_dtypes(include=['object', 'category']).columns.to_list()\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "                   [('scale', StandardScaler(), numeric_cols),\n",
    "                    ('onehot', OneHotEncoder(drop='first'), cat_cols)],\n",
    "                remainder='passthrough')\n",
    "\n",
    "X_train1 = preprocessor.fit_transform(X_train1)\n",
    "X_test1  = preprocessor.transform(X_test1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FEATURE SELECTION: SELECTKBEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir el output en dataframe y añadir el nombre de las columnas\n",
    "#==============================================================================\n",
    "encoded_cat = preprocessor.named_transformers_['onehot'].get_feature_names(cat_cols)\n",
    "labels = np.concatenate([numeric_cols, encoded_cat])\n",
    "#datos_train_prep = preprocessor.transform(X_train1)\n",
    "datos_train_prep = pd.DataFrame(X_train1, columns=labels)\n",
    "datos_test_prep=pd.DataFrame(X_test1,columns=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datos_train_prep.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FEATURE SELECTION: SELECTKBEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression, mutual_info_regression\n",
    "\n",
    "# Aplicando el algoritmo univariante de prueba F.\n",
    "k = 9  # número de atributos a seleccionar\n",
    "#columnas = list(X_train1.columns.values)\n",
    "seleccionadas = SelectKBest(mutual_info_regression, k=k).fit(datos_train_prep, y_train1)\n",
    "selected_features_df = pd.DataFrame({'Feature':list(datos_train_prep.columns),\n",
    "                                     'Scores MI':seleccionadas.scores_})\n",
    "selected_features_df.sort_values(by='Scores MI', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression, mutual_info_regression\n",
    "\n",
    "# Aplicando el algoritmo univariante de prueba F.\n",
    "k = 9  # número de atributos a seleccionar\n",
    "columnas = list(datos_train_prep.columns.values)\n",
    "seleccionadas = SelectKBest(f_regression, k=k).fit(datos_train_prep, y_train1)\n",
    "selected_features_df = pd.DataFrame({'Feature':list(datos_train_prep.columns),\n",
    "                                     'Scores f':seleccionadas.scores_})\n",
    "selected_features_df.sort_values(by='Scores f', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_indices = np.arange(datos_train_prep.shape[-1])\n",
    "scores = -np.log10(seleccionadas.pvalues_)\n",
    "scores /= scores.max()\n",
    "plt.bar(X_indices - .45, scores, width=.2,\n",
    "        label=r'Univariate score ($-Log(p_{value})$)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rfc = RandomForestRegressor(random_state=101)\n",
    "rfecv = RFECV(estimator=rfc, step=1, cv=10, scoring='r2')\n",
    "rfecv.fit(datos_train_prep, y_train1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Optimal number of features: {}'.format(rfecv.n_features_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "plt.title('Recursive Feature Elimination with Cross-Validation', fontsize=18, fontweight='bold', pad=20)\n",
    "plt.xlabel('Number of features selected', fontsize=14, labelpad=20)\n",
    "plt.ylabel('% R^2', fontsize=14, labelpad=20)\n",
    "plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_, color='#303F9F', linewidth=3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.where(rfecv.support_ == False)[0])\n",
    "\n",
    "datos_train_prep.drop(datos_train_prep.columns[np.where(rfecv.support_ == False)[0]], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sobrevivientes=datos_train_prep.columns\n",
    "datos_test_prep=datos_test_prep[sobrevivientes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = pd.DataFrame()\n",
    "dset['attr'] = datos_train_prep.columns\n",
    "dset['importance'] = rfecv.estimator_.feature_importances_\n",
    "\n",
    "dset = dset.sort_values(by='importance', ascending=False)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.barh(y=dset['attr'], width=dset['importance'], color='#1976D2')\n",
    "plt.title('RFECV - Feature Importances', fontsize=20, fontweight='bold', pad=20)\n",
    "plt.xlabel('Importance', fontsize=14, labelpad=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1=datos_train_prep\n",
    "X_test1=datos_test_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grid de hiperparámetros\n",
    "\n",
    "\n",
    "param_grid1={'hidden_layer_sizes':[(10,),(10,10),(10,10,10),(50,)],\n",
    "            'activation': ['relu'],\n",
    "            'alpha': [5,50,100,500],\n",
    "            'learning_rate': ['constant'],\n",
    "            'solver': ['adam']}\n",
    "                \n",
    "#scoring = {'neg_mean_absolute_error': 'neg_mean_absolute_error', 'neg_root_mean_squared_error': 'mean_squared_error'}\n",
    "\n",
    "\n",
    "\n",
    "# Búsqueda por validación cruzada\n",
    "\n",
    "grid1 = GridSearchCV(\n",
    "        estimator  = MLPRegressor() ,\n",
    "        param_grid = param_grid1,\n",
    "        n_jobs=-1,\n",
    "        cv         = 5,                      #RepeatedKFold(n_splits = 3, n_repeats = 5), \n",
    "        verbose    = 0,\n",
    "        return_train_score = True\n",
    "       )\n",
    "\n",
    "\n",
    "\n",
    "_=grid1.fit(X=X_train1, y=y_train1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=grid1.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resultados del grid\n",
    "# ==============================================================================\n",
    "resultados = pd.DataFrame(grid1.cv_results_)\n",
    "resultados.filter(regex = '(param.*|mean_t|std_t)')\\\n",
    "    .drop(columns = 'params')\\\n",
    "    .sort_values('mean_test_score', ascending = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Mejores hiperparámetros\n",
    "# ==============================================================================\n",
    "print(\"-----------------------------------\")\n",
    "print(\"Mejores hiperparámetros encontrados\")\n",
    "print(\"-----------------------------------\")\n",
    "print(grid1.best_params_, \":\", grid1.best_score_, grid1.scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = grid1.best_params_\n",
    "best_mlp1 = MLPRegressor(hidden_layer_sizes = best_params[\"hidden_layer_sizes\"], \n",
    "                        activation =best_params[\"activation\"],\n",
    "                        solver=best_params[\"solver\"], \n",
    "                        alpha=500,\n",
    "                        learning_rate=best_params[\"learning_rate\"],\n",
    "                        max_iter= 10000,\n",
    "                        n_iter_no_change = 1000,\n",
    "                        early_stopping=True,\n",
    "                        random_state=43\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grafico de ajuste del árbol de decisión\n",
    "from sklearn.metrics import r2_score\n",
    "from time import time\n",
    "tiempo_inicial=time()\n",
    "train_prec =  []\n",
    "eval_prec = []\n",
    "alpha1 = [5,50,500,1000]\n",
    "\n",
    "# Entrenar con arboles de distinta profundidad\n",
    "for deep in alpha1:\n",
    "    model = MLPRegressor(hidden_layer_sizes = best_params[\"hidden_layer_sizes\"], \n",
    "                        activation =best_params[\"activation\"],\n",
    "                        solver=best_params[\"solver\"], \n",
    "                        alpha=deep,\n",
    "                        learning_rate=best_params[\"learning_rate\"],\n",
    "                        max_iter= 10000,\n",
    "                        n_iter_no_change = 1000,\n",
    "                        early_stopping=True,\n",
    "                        random_state=43\n",
    "                       )\n",
    "    model.fit(X_train1, y_train1)\n",
    "    train_prec.append(model.score(X_train1, y_train1))\n",
    "    eval_prec.append(model.score(X_test1, y_test1))\n",
    "tiempo_final=time()\n",
    "print(tiempo_final-tiempo_inicial)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graficar los resultados.\n",
    "\n",
    "sns.set(rc={'figure.figsize':(12,9)})\n",
    "\n",
    "df1 = pd.DataFrame({'alpha':alpha1,\n",
    "                   'precision':train_prec,\n",
    "                   'datos':'entrenamiento'})\n",
    "\n",
    "df2 = pd.DataFrame({'alpha':alpha1,\n",
    "                   'precision':eval_prec,\n",
    "                   'datos':'evaluacion'})\n",
    "\n",
    "df_graph = pd.concat([df1,df2])\n",
    "\n",
    "sns.lineplot(data=df_graph,\n",
    "             x='alpha',\n",
    "             y='precision',\n",
    "             hue='datos',\n",
    "             palette=\"Set1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "best_mlp1 = MLPRegressor(hidden_layer_sizes = best_params[\"hidden_layer_sizes\"], \n",
    "                        activation =best_params[\"activation\"],\n",
    "                        solver=best_params[\"solver\"], \n",
    "                        alpha=500,#best_params[\"alpha\"],#500,\n",
    "                        learning_rate=best_params[\"learning_rate\"],\n",
    "                        max_iter= 10000,\n",
    "                        n_iter_no_change = 1000,\n",
    "                        early_stopping=True,\n",
    "                        random_state=42\n",
    "                       )\n",
    "\n",
    "best_mlp1.fit(X_train1,y_train1)\n",
    "predicciones=best_mlp1.predict(X_test1)\n",
    "\n",
    "\n",
    "#plt.scatter(y_test,pr.predict(X_test))\n",
    "fig, (ax1,ax2) = plt.subplots(2, figsize=(5, 5))\n",
    "\n",
    "ax1.scatter(y_train1, best_mlp1.predict(X_train1), edgecolors=(0, 0, 0),label='')\n",
    "ax1.plot([y_train1.min(), y_train1.max()], [y_train1.min(), y_train1.max()], 'k--', lw=4)\n",
    "#ax1.set_xlabel('PCI Medido')\n",
    "ax1.set_ylabel('PCI Predicho')\n",
    "\n",
    "ax1.set_title('Datos de Entrenamiento')\n",
    "\n",
    "\n",
    "ax2.scatter(y_train1, best_mlp1.predict(X_train1)-y_train1, edgecolors=(0, 0, 0),label='')\n",
    "ax2.plot([y_train1.min(), y_train1.max()], [0, 0], 'k--', lw=4)\n",
    "ax2.set_xlabel('PCI Medido')\n",
    "ax2.set_ylabel('PCI Residuos del Modelo')\n",
    "plt.ylim(-8, 8)\n",
    "#ax2.set_title('Datos de Entrenamiento')\n",
    "#ax1.plt.text(80,95,'$R^2$=0.9694')\n",
    "plt.show()\n",
    "from sklearn.metrics import r2_score\n",
    "print(\"r2\",r2_score(y_train1,best_mlp1.predict(X_train1)))\n",
    "print(\"MSE\",mean_squared_error(y_train1,best_mlp1.predict(X_train1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#plt.scatter(y_test,pr.predict(X_test))\n",
    "fig, (ax1,ax2) = plt.subplots(2, figsize=(5, 5))\n",
    "\n",
    "\n",
    "ax1.scatter(y_test1, best_mlp1.predict(X_test1), edgecolors=(0, 0, 0),label='')\n",
    "ax1.plot([y_test1.min(), y_test1.max()], [y_test1.min(), y_test1.max()], 'k--', lw=4)\n",
    "#ax1.set_xlabel('PCI Medido')\n",
    "ax1.set_ylabel('PCI Predicho')\n",
    "ax1.set_title('Datos de Prueba')\n",
    "#plt.text(80,95,'$R^2$=0.943')\n",
    "\n",
    "#plt.scatter(y_test,pr.predict(X_test))\n",
    "\n",
    "ax2.scatter(y_test1, best_mlp1.predict(X_test1)-y_test1, edgecolors=(0, 0, 0),label='')\n",
    "ax2.plot([y_test1.min(), y_test1.max()], [0, 0], 'k--', lw=4)\n",
    "ax2.set_xlabel('PCI Medido')\n",
    "ax2.set_ylabel('Residuos del modelo')\n",
    "plt.ylim(-7, 7)\n",
    "#ax1.set_title('Datos de Prueba')\n",
    "plt.show()\n",
    "print(\"r2\",r2_score(y_test1,best_mlp1.predict(X_test1)))\n",
    "print(\"MSE\",mean_squared_error(y_test1,best_mlp1.predict(X_test1)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANALISIS DE DATOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "libro=\"modelo.xlsx\"\n",
    "datos2=pd.read_excel(libro,sheet_name='Pruebas')\n",
    "datos_pro=datos2[[\"Ubicación\",\"Factor Sección Característica\",\"Tipo Pavimento\",\"Área (m2)\",\"NOMENCLATURA\",\"EDAD PAVIMENTO\",\"PCI\",\"DELTA PCI\",\"CARGA ACUMULADA RUEDA SIMPLE\",\"CARGA ACUMULADA RUEDA DOBLE\",\"CARGA ACUMULADA RUEDA DOBLE TANDEM\",\"OPERACIONES EQUIVALENTES\",\"CORREGIR EDAD-TRANSITO\",'PCI OBJETIVO']]\n",
    "datos_pro.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_proyecto=datos_pro.drop(['CARGA ACUMULADA RUEDA DOBLE', 'CARGA ACUMULADA RUEDA SIMPLE','CARGA ACUMULADA RUEDA DOBLE TANDEM','CORREGIR EDAD-TRANSITO','PCI OBJETIVO'], axis=1)\n",
    "x_proyecto['PCI']\n",
    "x_construccion=datos2['Año Construcción']\n",
    "x_seccion=datos2['Sección Característica']\n",
    "x_seccion\n",
    "\n",
    "d_PR= [\"PI-1\", \"PI-2\",\"PI-3\",\"PI-4\",\"PI-5\",\"PI-6\",\"PI-7\",\"PI-8\",\"PI-9\",\"PI-10\",\"RA-1\",\"RA-2\",\"DE-1\",\"DD-1\",\"DC-1\",\"DB-1\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_proyecto=datos_pro.drop(['CARGA ACUMULADA RUEDA DOBLE', 'CARGA ACUMULADA RUEDA SIMPLE','CARGA ACUMULADA RUEDA DOBLE TANDEM','CORREGIR EDAD-TRANSITO','PCI OBJETIVO'], axis=1)\n",
    "\n",
    "proyecciones = pd.DataFrame([])\n",
    "proyecciones1 = x_proyecto#pd.DataFrame([])\n",
    "PCI_t=x_proyecto['PCI']\n",
    "Edad_p=x_proyecto['EDAD PAVIMENTO']\n",
    "#Operaciones_eq=x_proyecto['EDAD Pavimento']\n",
    "\n",
    "\n",
    "\n",
    "for j in range(1,11):\n",
    "    #x_proyecto['PCI']=PCI_t\n",
    "    #x_proyecto['EDAD PAVIMENTO']=Edad_p\n",
    "    x1_proyecto = preprocessor.transform(x_proyecto)\n",
    "    x1_proyecto = pd.DataFrame(x1_proyecto, columns=labels)\n",
    "    x1_proyecto=x1_proyecto[sobrevivientes]\n",
    "    predicciones=best_mlp1.predict(x1_proyecto)\n",
    "    x_proyecto['PCI']=predicciones\n",
    "    x_proyecto['EDAD PAVIMENTO']+=1\n",
    "    opera=33.2613921169767*(((2013+j)**2)-((x_construccion)**2))-132975.883038438*(x_proyecto['EDAD PAVIMENTO'])\n",
    "    x_proyecto['OPERACIONES EQUIVALENTES']=opera\n",
    "    #33.2613921169767*(((AJ2)^2)-((M2)^2))-132975.883038438*(AJ2-M2)\n",
    "    #print(predicciones)\n",
    "    #print(x_proyecto['EDAD PAVIMENTO'])\n",
    "    #PCI_t=predicciones\n",
    "    #Edad_p+=1\n",
    "    #proyecciones=proyecciones.append({'Ubicación':x_proyecto['Ubicación'],\n",
    "    #                                  'Factor Sección Característica':x_proyecto['Factor Sección Característica'],\n",
    "    #                                  'Tipo Pavimento':x_proyecto['Tipo Pavimento'],\n",
    "    #                                  'Área (m2)':x_proyecto['Área (m2)'],\n",
    "    #                                  'NOMENCLATURA':x_proyecto['NOMENCLATURA'],\n",
    "    #                                  'EDAD PAVIMENTO':x_proyecto['EDAD PAVIMENTO'],\n",
    "    #                                  'PCI':x_proyecto['PCI'],\n",
    "    #                                  'DELTA PCI':x_proyecto['DELTA PCI'],\n",
    "    #                                  'OPERACIONES EQUIVALENTES':x_proyecto['OPERACIONES EQUIVALENTES'],\n",
    "    #                                  'Sección Característica': x_seccion\n",
    "    #                                 },ignore_index=True)\n",
    "    if 2013+j==2015:\n",
    "        x_proyecto['DELTA PCI'][0]=4  #PI-1\n",
    "        x_proyecto['DELTA PCI'][1]=10 #PI-2\n",
    "    elif 2013+j==2016:\n",
    "        #ACTUALES\n",
    "        x_proyecto['DELTA PCI'][10]=1  #RA-1\n",
    "        x_proyecto['DELTA PCI'][12]=5  #DE-1\n",
    "        x_proyecto['DELTA PCI'][14]=3  #DC-1\n",
    "        x_proyecto['DELTA PCI'][15]=1  #DB-1\n",
    "        #PASADOS\n",
    "        x_proyecto['DELTA PCI'][0]=0   #PI-1\n",
    "        x_proyecto['DELTA PCI'][1]=0   #PI-2\n",
    "    elif 2013+j==2017:\n",
    "        x_proyecto['DELTA PCI'][15]=1  #DB-1\n",
    "        #PASADOS\n",
    "        x_proyecto['DELTA PCI'][10]=0  #RA-1\n",
    "        x_proyecto['DELTA PCI'][12]=0  #DE-1\n",
    "        x_proyecto['DELTA PCI'][14]=0  #DC-1\n",
    "        x_proyecto['DELTA PCI'][15]=0  #DB-1\n",
    "    elif 2013+j==2018:\n",
    "        x_proyecto['DELTA PCI'][2]=2   #PI-3\n",
    "        x_proyecto['DELTA PCI'][0]=3   #PI-3\n",
    "         #PASADOS\n",
    "        x_proyecto['DELTA PCI'][15]=0  #DB-1\n",
    "    else:\n",
    "        x_proyecto['DELTA PCI']=0\n",
    "    x_proyecto1=x_proyecto\n",
    "    x_proyecto1['Sección Característica']=x_seccion\n",
    "    x_proyecto1['Año']=2013+j\n",
    "    proyecciones1= pd.concat([proyecciones1,x_proyecto1], axis=0)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask1=proyecciones1['Ubicación']=='Pista'\n",
    "#mask2=proyecciones1['Factor Sección Característica']=='Sector central de pista'\n",
    "mask3=proyecciones1['Año']==2016\n",
    "mask4=proyecciones1['Área (m2)']==1760\n",
    "proyecciones1[mask1&mask3&mask4].head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xgra=datos[[\"Ubicación\",'Sección Característica','AÑO EVALUACIÓN',\"Factor Sección Característica\",\"Tipo Pavimento\",\"Área (m2)\",\"NOMENCLATURA\",\"EDAD PAVIMENTO\",\"PCI\",\"DELTA PCI\",\"CARGA ACUMULADA RUEDA SIMPLE\",\"CARGA ACUMULADA RUEDA DOBLE\",\"CARGA ACUMULADA RUEDA DOBLE TANDEM\",\"OPERACIONES EQUIVALENTES\",\"CORREGIR EDAD-TRANSITO\"]]\n",
    "x_medido=xgra[['Sección Característica','AÑO EVALUACIÓN','PCI']]\n",
    "x_medido = x_medido.rename(columns={\"AÑO EVALUACIÓN\": \"Año\"})\n",
    "x_medido['Dato']=\"Medido\"\n",
    "x_proyectado=proyecciones1[['Sección Característica','Año','PCI']]\n",
    "x_proyectado['Dato']=\"Predicho\"\n",
    "frames = [x_medido, x_proyectado]\n",
    "datos_analisis = pd.concat(frames)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fil=datos_analisis['Sección Característica'].isin(d_PR)\n",
    "datos_analisis=datos_analisis[fil]\n",
    "import seaborn as sns\n",
    "sns.set_theme(style=\"ticks\")\n",
    "##sns.catplot(x=\"Año\", y=\"PCI\",col=\"Sección Característica\", data=proyecciones1,ax=ax)\n",
    "#sns.relplot(data=proyecciones1, x=\"Año\", y=\"PCI\",col=\"Sección Característica\",ax=ax1)\n",
    "#sns.relplot(data=xgra, x=\"AÑO EVALUACIÓN\", y=\"PCI\",col=\"Sección Característica\",ax=ax1)\n",
    "\n",
    "sns.catplot(x=\"Año\", y=\"PCI\",col=\"Sección Característica\", hue=\"Dato\",data=datos_analisis,kind='strip',col_wrap=2,margin_titles=True)\n",
    "plt.ylim(0, 101)\n",
    "#ax.legend(['alpha', 'beta'], facecolor='w')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
